# -*- coding: utf-8 -*-
"""DecisionTree_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OcQL8D_S_IlFvh4Y7hxR5crrhBJZQsRQ
"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score

# Load the training data
training_data = pd.read_csv('https://raw.githubusercontent.com/juliw9/FrenchLanguageClassifier/main/Data/training_data.csv')

# Split the data into features and labels
X = training_data['sentence']
y = training_data['difficulty']

# Convert sentences to TF-IDF features
vectorizer = TfidfVectorizer()
X_tfidf = vectorizer.fit_transform(X)

# Split the data into training and test sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Define the Decision Tree classifier
dt = DecisionTreeClassifier(random_state=42)

# Define a more refined grid of hyperparameters to search
param_grid = {
    'criterion': ['entropy'],
    'max_depth': [None, 10, 20, 30, 40],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4, 6],
    'max_features': [None, 'sqrt', 'log2']
}

# Perform grid search with cross-validation
grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Get the best parameters
best_params = grid_search.best_params_
print(f'Best parameters: {best_params}')

# Train the Decision Tree classifier with the best parameters
dt_best = DecisionTreeClassifier(**best_params, random_state=42)
dt_best.fit(X_train, y_train)

# Predict the difficulty of the test set
y_pred = dt_best.predict(X_test)

# Evaluate the accuracy, F1 score, recall, and precision
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')

print(f'Test Set Accuracy: {accuracy:.2f}')
print(f'Test Set F1 Score: {f1:.2f}')
print(f'Test Set Recall: {recall:.2f}')
print(f'Test Set Precision: {precision:.2f}')

# Load the unlabelled data
unlabelled_data = pd.read_csv('https://raw.githubusercontent.com/juliw9/FrenchLanguageClassifier/main/Data/unlabelled_test_data.csv')
X_unlabelled = unlabelled_data['sentence']

# Convert unlabelled sentences to TF-IDF features using the same vectorizer
X_unlabelled_tfidf = vectorizer.transform(X_unlabelled)

# Predict the difficulty of the unlabelled data
unlabelled_predictions = dt_best.predict(X_unlabelled_tfidf)

# Create a DataFrame for the predictions including the id column
submission = pd.DataFrame({
    'id': unlabelled_data['id'],
    'difficulty': unlabelled_predictions
})

# Save the predictions to a CSV file
submission.to_csv('submission_DecisionTree.csv', index=False)

print('Predictions saved to submission_DecisionTree.csv')