# -*- coding: utf-8 -*-
"""LogisticRegression_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15NL_EFk9ZvOSkv6oxJR4pR1auCOpGOPT
"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score

# Load the training data
training_data = pd.read_csv('https://raw.githubusercontent.com/juliw9/FrenchLanguageClassifier/main/Data/training_data.csv')

# Split the data into features and labels
X = training_data['sentence']
y = training_data['difficulty']

# Convert sentences to TF-IDF features
vectorizer = TfidfVectorizer()
X_tfidf = vectorizer.fit_transform(X)

# Split the data into training and test sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Define the Logistic Regression classifier
lr = LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial')

# Define the grid of hyperparameters to search
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],
    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],
    'penalty': ['l2', 'none']  # Note: 'elasticnet' requires the 'l1_ratio' parameter and solver 'saga'
}

# Perform grid search with cross-validation
grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Get the best parameters
best_params = grid_search.best_params_
print(f'Best parameters: {best_params}')

# Train the Logistic Regression classifier with the best parameters
lr_best = LogisticRegression(**best_params, random_state=42, max_iter=1000, multi_class='multinomial')
lr_best.fit(X_train, y_train)

# Predict the difficulty of the test set
y_pred = lr_best.predict(X_test)

# Evaluate the accuracy, F1 score, recall, and precision
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')

print(f'Test Set Accuracy: {accuracy:.2f}')
print(f'Test Set F1 Score: {f1:.2f}')
print(f'Test Set Recall: {recall:.2f}')
print(f'Test Set Precision: {precision:.2f}')

# Load the unlabelled data
unlabelled_data = pd.read_csv('https://raw.githubusercontent.com/juliw9/FrenchLanguageClassifier/main/Data/unlabelled_test_data.csv')
X_unlabelled = unlabelled_data['sentence']

# Convert unlabelled sentences to TF-IDF features using the same vectorizer
X_unlabelled_tfidf = vectorizer.transform(X_unlabelled)

# Predict the difficulty of the unlabelled data
unlabelled_predictions = lr_best.predict(X_unlabelled_tfidf)

# Create a DataFrame for the predictions including the id column
submission = pd.DataFrame({
    'id': unlabelled_data['id'],
    'difficulty': unlabelled_predictions
})

# Save the predictions to a CSV file
submission.to_csv('submission_LogisticRegression.csv', index=False)

print('Predictions saved to submission_LogisticRegression.csv')